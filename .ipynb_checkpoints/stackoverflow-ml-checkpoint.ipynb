{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "codeCollapsed": false,
    "hiddenCell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: google-cloud-bigquery in /usr/local/envs/py3env/lib/python3.5/site-packages (1.5.1)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media>=0.2.1 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-cloud-bigquery) (0.3.1)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<0.29dev,>=0.28.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-cloud-bigquery) (0.28.1)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.0.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-cloud-bigquery) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-resumable-media>=0.2.1->google-cloud-bigquery) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2.0.0dev,>=0.4.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (1.5.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (2016.7)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (3.5.2)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.5.3 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (1.5.3)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (2.18.4)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=34.0.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (40.0.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (3.4.2)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/envs/py3env/lib/python3.5/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/envs/py3env/lib/python3.5/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/envs/py3env/lib/python3.5/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (1.22)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/envs/py3env/lib/python3.5/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (2018.8.13)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/envs/py3env/lib/python3.5/site-packages (from rsa>=3.1.4->google-auth<2.0.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict response time on Stackoverflow questions based on Bigquery stackoverflow public dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Data from bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Instantiates a client\n",
    "bigquery_client = bigquery.Client(project='hackertone-216701')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust WHERE clause based on trainning volume, avg_ans_sec <= 7200 took 5min \n",
    "QUERY = \"\"\"\n",
    "    SELECT title,avg_ans_sec FROM `stackoverflow_summary.post_accepted_answers` WHERE avg_ans_sec <= 3600 \"\"\"\n",
    "\n",
    "# Or, querying dataset based on input words\n",
    "# QUERY = \"\"\"\n",
    "#     SELECT title,avg_ans_sec FROM `stackoverflow_summary.post_accepted_answers` WHERE lower(title) like '%javascript%' \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting query... ok.\n",
      "Job ID: 5a60ee6a-df74-4c83-b67c-ca30006acc9c\n",
      "Query running...\n",
      "  Elapsed 7.05 s. Waiting...\n",
      "  Elapsed 8.2 s. Waiting...\n",
      "  Elapsed 9.33 s. Waiting...\n",
      "  Elapsed 10.46 s. Waiting...\n",
      "  Elapsed 11.64 s. Waiting...\n",
      "  Elapsed 12.77 s. Waiting...\n",
      "  Elapsed 13.91 s. Waiting...\n",
      "  Elapsed 15.05 s. Waiting...\n",
      "  Elapsed 16.19 s. Waiting...\n",
      "  Elapsed 17.32 s. Waiting...\n",
      "  Elapsed 18.44 s. Waiting...\n",
      "  Elapsed 19.58 s. Waiting...\n",
      "  Elapsed 20.71 s. Waiting...\n",
      "  Elapsed 21.83 s. Waiting...\n",
      "  Elapsed 22.96 s. Waiting...\n",
      "  Elapsed 24.1 s. Waiting...\n",
      "  Elapsed 25.24 s. Waiting...\n",
      "  Elapsed 26.38 s. Waiting...\n",
      "  Elapsed 27.52 s. Waiting...\n",
      "  Elapsed 28.64 s. Waiting...\n",
      "  Elapsed 29.78 s. Waiting...\n",
      "  Elapsed 30.92 s. Waiting...\n",
      "Query done.\n",
      "Processed: 399.0 MB Billed: 400.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Retrieving results...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_gbq as gbq\n",
    "\n",
    "project_id = 'hackertone-216701'\n",
    "post_accepted_answers = gbq(QUERY,project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize or Scale avg_ans_sec for performance improvement \n",
    "# If scale the avg_ans_sec, not easy to reverse values to original, if we reduce avg_ans_sec under 10 thousands prediction is not bad \n",
    "# from sklearn.preprocessing import scale\n",
    "\n",
    "# post_accepted_answers['avg_ans_sec_norm'] = scale(post_accepted_answers.avg_ans_sec.values)\n",
    "# post_accepted_answers.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test set \n",
    "X_train , X_test, y_train, y_test = train_test_split(post_accepted_answers.title, post_accepted_answers.avg_ans_sec, test_size=0.30, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize title to words\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# count_vect = CountVectorizer(lowercase=True, min_df=5)\n",
    "# X_train_counts = count_vect.fit_transform(X_train)\n",
    "# X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighting title based on TF-IDF \n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Pipeline for less code \n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Supper Vector Machines Algorithm\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Can not implement classification cause for not unique feature\n",
    "# text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf-svm', SGDClassifier(loss='hinge',penalty='l2',random_state=42))])\n",
    "\n",
    "text_reg_svm = Pipeline([('vect', CountVectorizer(stop_words='english',min_df=20)), ('tfidf', TfidfTransformer(use_idf=True)), ('reg-svm', SGDRegressor(penalty='l2',random_state=42,alpha=1e-3))])\n",
    "_ = text_reg_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_reg_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict diff average:4140.02508909744\n",
      "predict diff variance:94180681.98036969\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cacluate Average Error Rate in Seconds\n",
    "print(\"predict diff average:{}\\npredict diff variance:{}\\n\".format(np.mean(abs(predicted_svm - y_test)), np.var(predicted_svm - y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "#               'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'vect__min_df':[5,20],\n",
    "#               'tfidf__use_idf': (True, False),\n",
    "#               'reg-svm__alpha': (1e-2, 1e-3),\n",
    "             }\n",
    "\n",
    "gs_clf = GridSearchCV(text_reg_svm, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__min_df': 20}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_    \n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real World Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JavaScript why this mod operation return undefined [on hold]           | real response:   360.000 | predict :  2287.264 | diff :  1927.264 \n",
      "\n",
      "BigQuery authorization                                                 | real response: 14700.000 | predict :  2215.474 | diff :-12484.526 \n",
      "\n",
      "Replace function not working for long query in ORACLE/PLSQL?           | real response:  2400.000 | predict :  2379.804 | diff :   -20.196 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Real world testing , stackoverflow queries after dataset being created.\n",
    "test_query = {'title':['JavaScript why this mod operation return undefined [on hold]',\n",
    "                       'BigQuery authorization',\n",
    "                       'Replace function not working for long query in ORACLE/PLSQL?'],\n",
    "              'response':[360,14700,2400]}\n",
    "df = pd.DataFrame(data=test_query)\n",
    "test_predict = text_reg_svm.predict(df.title)\n",
    "\n",
    "i=0\n",
    "for _,row in df.iterrows():\n",
    "  print(\"{:70s} | real response:{:10.3f} | predict :{:10.3f} | diff :{:10.3f} \\n\".format(row.title, row.response,test_predict[i],test_predict[i] - row.response))\n",
    "  i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

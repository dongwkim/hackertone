{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빅쿼리 퍼블릭 데이터 셋을 이용해서 내 질문에 따른 Stackoverflow 응답시간 예측하기  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 빅쿼리로 부터 질문에 따른 응답시간 데이터 수신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Instantiates a client\n",
    "bigquery_client = bigquery.Client(project='hackertone-216701')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust WHERE clause based on trainning volume, avg_ans_sec <= 7200 took 5min \n",
    "QUERY = \"\"\"\n",
    "    SELECT title,avg_ans_sec/60 as avg_ans_min FROM `stackoverflow_summary.post_accepted_answers` WHERE avg_ans_sec <= 2*3600 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting query... ok.\n",
      "Job ID: 7f29fe90-41fa-4418-815c-b2b525ab3444\n",
      "Query running...\n",
      "Query done.\n",
      "Cache hit.\n",
      "\n",
      "Retrieving results...\n",
      "Got 5500222 rows.\n",
      "\n",
      "Total time taken 252.42 s.\n",
      "Finished at 2018-10-05 12:09:29.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_gbq as gbq\n",
    "\n",
    "project_id = 'hackertone-216701'\n",
    "post_accepted_answers = gbq(QUERY,project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize or Scale avg_ans_sec for performance improvement \n",
    "# If scale the avg_ans_sec, not easy to reverse values to original, if we reduce avg_ans_sec under 10 thousands prediction is not bad \n",
    "# from sklearn.preprocessing import scale\n",
    "\n",
    "# post_accepted_answers['avg_ans_sec_norm'] = scale(post_accepted_answers.avg_ans_sec.values)\n",
    "# post_accepted_answers.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 데이터를 Training Set 과 Test Set 으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test set \n",
    "X_train , X_test, y_train, y_test = train_test_split(post_accepted_answers.title, post_accepted_answers.avg_ans_min, test_size=0.3, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize title to words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# count_vect = CountVectorizer(lowercase=True, min_df=5)\n",
    "# X_train_counts = count_vect.fit_transform(X_train)\n",
    "# X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighting title based on TF-IDF \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Pipeline for less code \n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_rate(predict,y_test):\n",
    "  print(\"Predicted diff average:{:5f}\\npredict diff variance:{:7f}\\n\".format(np.mean(abs(predict - y_test)), np.var(abs(predict - y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false \n",
    "\n",
    "## Use Supper Vector Machines Algorithm\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Can not implement classification cause for not unique feature\n",
    "# text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf-svm', SGDClassifier(loss='hinge',penalty='l2',random_state=42))])\n",
    "\n",
    "text_reg_svm = Pipeline([('vect', CountVectorizer(stop_words='english',min_df=20)), ('tfidf', TfidfTransformer(use_idf=True)), ('reg-svm', SGDRegressor(penalty='l2',random_state=42,alpha=1e-3))])\n",
    "sgd_model = text_reg_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_reg_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted diff average:19.471370\n",
      "predict diff variance:291.939576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%script false \n",
    "\n",
    "# Cacluate Average Error Rate in Seconds\n",
    "get_error_rate(predicted_svm, y_test)\n",
    "#print(\"predict diff average:{:5f}\\npredict diff variance:{:7f}\\n\".format(np.mean(abs(predicted_svm - y_test)), np.var(abs(predicted_svm - y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false \n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "text_dt_reg = Pipeline([('vect', CountVectorizer(stop_words='english',min_df=20)), ('tfidf', TfidfTransformer(use_idf=True)), ('reg-dt', DecisionTreeRegressor(random_state=42))])\n",
    "dt_model = text_dt_reg.fit(X_train, y_train)\n",
    "predicted_dt = text_dt_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "# Cacluate Average Error Rate in Seconds\n",
    "print(\"predict diff average:{:5f}\\npredict diff variance:{:7f}\\n\".format(np.mean(abs(predicted_dt - y_test)), np.var(abs(predicted_dt - y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "text_rf_reg = Pipeline([('vect', CountVectorizer(stop_words='english',min_df=20)), ('tfidf', TfidfTransformer(use_idf=True)), ('reg-rf', RandomForestRegressor(random_state=42,max_depth=4,n_jobs=-1,n_estimators=10,verbose=0))])\n",
    "rf_model = text_rf_reg.fit(X_train, y_train)\n",
    "predicted_rf = text_rf_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted diff average:19.844678\n",
      "predict diff variance:297.943198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%script true\n",
    "# Cacluate Average Error Rate in Seconds\n",
    "get_error_rate(predicted_rf,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle을 사용해서 ML Engine 으로 전송하기 위한 Model 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'model.pkl'\n",
    "pickle.dump(rf_model, open(filename,'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "#               'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#               'vect__min_df':[5,20],\n",
    "#               'tfidf__use_idf': (True, False),\n",
    "              'reg-svm__alpha': (1e-2, 1e-3),\n",
    "             }\n",
    "\n",
    "gs_clf = GridSearchCV(text_reg_svm, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false \n",
    "gs_clf.best_score_    \n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real World Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JavaScript why this mod operation return undefined [on hold]           | real response:     6.000 | predict :    18.778 | diff :    12.778 \n",
      "\n",
      "BigQuery authorization                                                 | real response:   240.000 | predict :    25.077 | diff :   214.923 \n",
      "\n",
      "Replace function not working for long query in ORACLE/PLSQL?           | real response:    40.000 | predict :    25.077 | diff :    14.923 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Real world testing , stackoverflow queries after dataset being created.\n",
    "test_query = {'title':['JavaScript why this mod operation return undefined [on hold]',\n",
    "                       'BigQuery authorization',\n",
    "                       'Replace function not working for long query in ORACLE/PLSQL?'],\n",
    "              'response':[6,240,40]}\n",
    "df = pd.DataFrame(data=test_query)\n",
    "test_predict = text_rf_reg.predict(df.title)\n",
    "\n",
    "i=0\n",
    "for _,row in df.iterrows():\n",
    "  print(\"{:70s} | real response:{:10.3f} | predict :{:10.3f} | diff :{:10.3f} \\n\".format(row.title, row.response,test_predict[i],abs(test_predict[i] - row.response)))\n",
    "  i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

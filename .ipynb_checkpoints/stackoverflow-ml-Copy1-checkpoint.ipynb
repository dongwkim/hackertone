{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "codeCollapsed": false,
    "hiddenCell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: google-cloud-bigquery in /usr/local/envs/py3env/lib/python3.5/site-packages (1.5.1)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<0.29dev,>=0.28.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-cloud-bigquery) (0.28.1)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media>=0.2.1 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-cloud-bigquery) (0.3.1)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.0.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-cloud-bigquery) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-resumable-media>=0.2.1->google-cloud-bigquery) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=34.0.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (40.0.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (2.18.4)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2.0.0dev,>=0.4.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (1.5.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (3.5.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (2016.7)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.5.3 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (1.5.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/envs/py3env/lib/python3.5/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/envs/py3env/lib/python3.5/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/envs/py3env/lib/python3.5/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (1.22)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/envs/py3env/lib/python3.5/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (2018.8.13)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (3.4.2)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/envs/py3env/lib/python3.5/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/envs/py3env/lib/python3.5/site-packages (from rsa>=3.1.4->google-auth<2.0.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict response time on Stackoverflow questions based on Bigquery stackoverflow public dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Instantiates a client\n",
    "bigquery_client = bigquery.Client(project='hackertone-216701')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust WHERE clause based on trainning volume, avg_ans_sec <= 7200 took 5min \n",
    "QUERY = \"\"\"\n",
    "    SELECT title,avg_ans_sec FROM `stackoverflow_summary.post_accepted_answers` WHERE avg_ans_sec <= 7200 \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting query... ok.\n",
      "Job ID: f397b589-5e58-42d8-94ec-86c1d87b2532\n",
      "Query running...\n",
      "  Elapsed 7.05 s. Waiting...\n",
      "  Elapsed 8.18 s. Waiting...\n",
      "  Elapsed 9.32 s. Waiting...\n",
      "  Elapsed 10.44 s. Waiting...\n",
      "  Elapsed 11.57 s. Waiting...\n",
      "  Elapsed 12.71 s. Waiting...\n",
      "  Elapsed 13.83 s. Waiting...\n",
      "  Elapsed 14.96 s. Waiting...\n",
      "  Elapsed 16.08 s. Waiting...\n",
      "  Elapsed 17.21 s. Waiting...\n",
      "  Elapsed 18.33 s. Waiting...\n",
      "  Elapsed 19.47 s. Waiting...\n",
      "  Elapsed 20.62 s. Waiting...\n",
      "  Elapsed 21.76 s. Waiting...\n",
      "  Elapsed 22.88 s. Waiting...\n",
      "  Elapsed 23.99 s. Waiting...\n",
      "  Elapsed 25.12 s. Waiting...\n",
      "  Elapsed 26.24 s. Waiting...\n",
      "  Elapsed 27.36 s. Waiting...\n",
      "  Elapsed 28.49 s. Waiting...\n",
      "  Elapsed 29.61 s. Waiting...\n",
      "  Elapsed 30.76 s. Waiting...\n",
      "  Elapsed 31.89 s. Waiting...\n",
      "Query done.\n",
      "Processed: 399.0 MB Billed: 400.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Retrieving results...\n",
      "Got 5500222 rows.\n",
      "\n",
      "Total time taken 296.62 s.\n",
      "Finished at 2018-10-01 06:34:34.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_gbq as gbq\n",
    "\n",
    "project_id = 'hackertone-216701'\n",
    "post_accepted_answers = gbq(QUERY,project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize or Scale avg_ans_sec for performance improvement \n",
    "# If scale the avg_ans_sec, not easy to reverse values to original, if we reduce avg_ans_sec under 10 thousands prediction is not bad \n",
    "# from sklearn.preprocessing import scale\n",
    "\n",
    "# post_accepted_answers['avg_ans_sec_norm'] = scale(post_accepted_answers.avg_ans_sec.values)\n",
    "# post_accepted_answers.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test set \n",
    "X_train , X_test, y_train, y_test = train_test_split(post_accepted_answers.title, post_accepted_answers.avg_ans_sec, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3685148, 44323)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize title to words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(lowercase=True, min_df=5)\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3685148, 213423)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighting title based on TF-IDF \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Pipeline for less code \n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## Use Supper Vector Machines Algorithm\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Can not implement classification cause for not unique feature\n",
    "# text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf-svm', SGDClassifier(loss='hinge',penalty='l2',random_state=42))])\n",
    "\n",
    "text_reg_svm = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('reg-svm', SGDRegressor(penalty='l2',random_state=42))])\n",
    "_ = text_reg_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_reg_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict diff average:-4.269388626194557\n",
      "predict diff variance:2379537.402369696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cacluate Average Error Rate in Seconds\n",
    "print(\"predict diff average:{}\\npredict diff variance:{}\\n\".format(np.mean(predicted_svm - y_test), np.var(predicted_svm - y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Can not implement classification cause for not unique feature\n",
    "# text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf-svm', SGDClassifier(loss='hinge',penalty='l2',random_state=42))])\n",
    "\n",
    "text_log_reg = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('log-reg', LogisticRegression(random_state=42))])\n",
    "_ = text_log_reg.fit(X_train, y_train)\n",
    "predicted_lr = text_log_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cacluate Average Error Rate in Seconds\n",
    "print(\"predict diff average:{}\\npredict diff variance:{}\\n\".format(np.mean(predicted_lr - y_test), np.var(predicted_lr - y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real World Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JavaScript why this mod operation return undefined [on hold]           | real response:   360.000 | predict :  1066.657 | diff :   706.657 \n",
      "\n",
      "BigQuery authorization                                                 | real response: 14700.000 | predict :  1876.356 | diff :-12823.644 \n",
      "\n",
      "Replace function not working for long query in ORACLE/PLSQL?           | real response:  2400.000 | predict :  1406.725 | diff :  -993.275 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Real world testing , stackoverflow queries after dataset being created.\n",
    "test_query = {'title':['JavaScript why this mod operation return undefined [on hold]',\n",
    "                       'BigQuery authorization',\n",
    "                       'Replace function not working for long query in ORACLE/PLSQL?'],\n",
    "              'response':[360,14700,2400]}\n",
    "df = pd.DataFrame(data=test_query)\n",
    "test_predict = text_reg_svm.predict(df.title)\n",
    "\n",
    "i=0\n",
    "for _,row in df.iterrows():\n",
    "  print(\"{:70s} | real response:{:10.3f} | predict :{:10.3f} | diff :{:10.3f} \\n\".format(row.title, row.response,test_predict[i],test_predict[i] - row.response))\n",
    "  i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BigQuery authorization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
